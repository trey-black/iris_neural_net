{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import torchmetrics\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import CrossEntropyLoss\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a Neural Network:\n",
    "\n",
    "1. ~~Create a model~~\n",
    "2. Choose a loss function\n",
    "3. Create a dataset\n",
    "4. Define an optimizer\n",
    "5. Run a training loop, where for each sample of the dataset, we repeat: (akin to .fit in sklearn)\n",
    "    - Calculating loss (forward pass)\n",
    "    - Calculating local gradients (backward pass)\n",
    "    - Updating model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DATA PROCESSING\n",
    "\n",
    "# np_array = np.array(array)\n",
    "# np_tensor = torch.from_numpy(np_array)\n",
    "\n",
    "data_pd = pd.read_csv('~/Documents/Data Science/programs/iris_neural_net/iris_data.csv')\n",
    "\n",
    "x = data_pd.drop(['species'], axis=1)\n",
    "y = data_pd.species\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "y = encoder.fit_transform(y)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x = scaler.fit_transform(x)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.25, random_state = 888)\n",
    "\n",
    "features = torch.from_numpy(x_train)\n",
    "labels = F.one_hot(torch.from_numpy(y_train))\n",
    "\n",
    "# print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0274,  0.0054,  0.0220])\n"
     ]
    }
   ],
   "source": [
    "### FORWARD PASS\n",
    "\n",
    "dataset = TensorDataset(features.float(), labels.float())\n",
    "dataloader = DataLoader(dataset, batch_size=4, shuffle=True)\n",
    "num_epochs = 10\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(4, 6),\n",
    "    nn.Linear(6, 3),\n",
    "    nn.Softmax(dim=-1)\n",
    ")\n",
    "\n",
    "scores = model(input)\n",
    "# _, preds = torch.max(output, dim=1)\n",
    "# preds = F.one_hot(preds, num_classes=3)\n",
    "\n",
    "# CrossEntropyLoss for classification, MSELoss for regression\n",
    "criterion = CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for data in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        feature, target = data\n",
    "        pred = model(feature)\n",
    "        loss = criterion(pred, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "print(model[1].bias.grad)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
